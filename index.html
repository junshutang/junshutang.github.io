<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title> Junshu Tang (唐俊姝) </title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="A2nXUugMvMH5Xy0yLCrnLyU0jySYHhQGTZwju8WLFCk" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">
  <link rel="dns-prefetch" href="https://www.google-analytics.com">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Junshu Tang (唐俊姝) </name>  <br> <br>
              </p>
              <p style="font-family:verdana"> I am currently a senior researcher at Tencent Hunyuan Team. I obtained my PhD degree at the Shanghai Jiao Tong University (<a href="https://www.sjtu.edu.cn/">SJTU</a>), advised by <a href="https://dmcv.sjtu.edu.cn/">Lizhuang Ma</a>. 
                <br> Before that, I was a research intern at Tencent Youtu Lab. In 2023, I was a research intern at OpenMMLab, Shanghai AI Lab, working with <a href="https://zengyh1900.github.io/">Yanhong Zeng</a> and <a href="https://daibo.info/">Bo Dai</a>.
		<br> From 2021 to 2023, I was a research intern at Visual Computing Group, Microsoft Research Asia (MSRA), working with <a href="https://bo-zhang.me/">Bo Zhang</a> and <a href="http://www.dongchen.pro/">Dong Chen</a>.
                <br> I'm interested in 2D/3D content generation and animation, mainly focus on face/body animation and 3D generation.  
              </p>
 
 	      <p style="color:red;">Looking for research interns and collaboration, feel free to contact me through the email.</p>
              <p style="text-align:center">
                <a href="mailto:tangjs@sjtu.edu.cn"> Email</a> &nbsp/&nbsp
                <a href="https://github.com/junshutang"> Github</a> &nbsp/&nbsp 
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=ad_WbwMAAAAJ">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="images/tjs.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
                                                                                                                          
                                                                                                                          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tbody>
                  <tr>
                    <td>
                      <heading>News</heading>
                      <p>
                      <ul>
			<li><strong>News (Dec 2024): Two papers are accepted to AAAI 2025.</strong></li>
			<li>News (Aug 2024): <a href="https://ggxxii.github.io/texdreamer/">TexDreamer</a> is accepted to ECCV 2024 as Oral.</li>
			<li>News (Jul 2024): Two papers are accepted to ECCV 2024.</li>
			<li>News (Feb 2024): One paper is accepted to CVPR 2024.</li>
                        <li>News (Sep 2023): One paper is accepted to TVCG 2023.</li>
                        <li>News (Jul 2023): One paper is accepted to ICCV 2023.</li>
                        <li>News (Jul 2023): One paper is accepted to CAD/Graphics 2023.</li>
                        <li>News (Mar 2022): One paper is accepted to CVPR 2022.</li>
                        <li>News (Apr 2021): One paper is accepted to TIP 2021.</li>
                        <li>News (Feb 2021): One paper is accepted to IEEE Multimedia 2021.</li>
                        <li>News (Mar 2020): One paper is accepted to ICME 2020 as Oral presentation.</li>
                      </ul>
                      </p>
                    </td>
                  </tr>
                </tbody>
        </tbody></table>
 
        <heading>Publications</heading>
        <!-- <p> (* indicates joint first authors) </p> -->
        <p> (*equal contribution, ^intern) </p>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="gamecraft_stop()" onmouseover="gamecraft_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='gamecraft_image'><video  width=100% height=100% muted autoplay loop>
                <source src="videos/gamecraft.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/gamecraft.png' width="160">
              </div>
              <script type="text/javascript">
                function gamecraft_start() {
                  document.getElementById('gamecraft_image').style.opacity = "1";
                }

                function gamecraft_stop() {
                  document.getElementById('gamecraft_image').style.opacity = "0";
                }
                gamecraft_stop()
              </script>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition
                </papertitle>
                <br>
                Jiaqi Li^*, <strong>Junshu Tang*</strong>, Zhiyong Xu, Longhuang Wu, Yuan Zhou, Shuai Shao, Tianbao Yu, Zhiguo Cao, Qinglin Lu
                <br>
                              <em>Technical Report</em>, 2025
                <br>
                <a href="https://hunyuan-gamecraft.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2506.17201">paper</a>
                <p></p>
                <p></p>
              </td>
            </tr> 



          <tr onmouseout="game_stop()" onmouseover="game_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                          <div class="two" id='game_image'><video  width=100% height=100% muted autoplay loop>
                          <source src="videos/game.mp4" type="video/mp4">
                          Your browser does not support the video tag.
                          </video></div>
                          <img src='images/game.jpeg' width="160">
                        </div>
                        <script type="text/javascript">
                          function game_start() {
                            document.getElementById('game_image').style.opacity = "1";
                          }
          
                          function game_stop() {
                            document.getElementById('game_image').style.opacity = "0";
                          }
                          game_stop()
                        </script>
                      </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>Hunyuan-Game: Industrial-grade Intelligent Game Creation Model</papertitle>
                          <br>
                          Hunyuan MultiModal Model Team
                          <br>
                                        <em>Technical Report</em>, 2025
                          <br>
                          <a href="https://hunyuan.tencent.com/hunyuan-game">project page</a>
                          /
                          <a href="https://arxiv.org/abs/2505.14135">paper</a>
                          <p></p>
                          <p></p>
                        </td>
                      </tr> 

          <tr onmouseout="avatar_stop()" onmouseover="avatar_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='avatar_image'><video  width=100% height=100% muted autoplay loop>
                <source src="videos/avatar.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/avatar.png' width="160">
              </div>
              <script type="text/javascript">
                function avatar_start() {
                  document.getElementById('avatar_image').style.opacity = "1";
                }

                function avatar_stop() {
                  document.getElementById('avatar_image').style.opacity = "0";
                }
                avatar_stop()
              </script>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters</papertitle>
                <br>
                Yi Chen, Sen Liang, Zixiang Zhou, Ziyao Huang, Yifeng Ma, <strong>Junshu Tang</strong>, Qin Lin, Yuan Zhou, Qinglin Lu
                <br>
                              <em>Technical Report</em>, 2025
                <br>
                <a href="https://hunyuanvideo-avatar.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2505.20156">paper</a>
                /
                <a href="https://hunyuanvideo-avatar.github.io/">code</a>
                /
                <a href="https://hunyuan.tencent.com/modelSquare/home/play?modelId=126">demo</a>
                <p></p>
                <p></p>
              </td>
            </tr> 

		<tr onmouseout="cloth_stop()" onmouseover="cloth_start()">
		<td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
	                <div class="two" id='cloth_image'><video  width=100% height=100% muted autoplay loop>
	                <source src="videos/cloth.mp4" type="video/mp4">
	                Your browser does not support the video tag.
	                </video></div>
	                <img src='images/cloth.png' width="160">
	              </div>
	              <script type="text/javascript">
	                function cloth_start() {
	                  document.getElementById('cloth_image').style.opacity = "1";
	                }
	
	                function cloth_stop() {
	                  document.getElementById('cloth_image').style.opacity = "0";
	                }
	                cloth_stop()
	              </script>
	            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians</papertitle>
                  <br>
			Yufei Liu, <strong>Junshu Tang</strong>, Chu Zheng, Shijie Zhang, Jinkun Hao, Junwei Zhu, Dongjin Huang
                  <br>
                                <em>arXiv</em>, 2024
                  <br>
		  <a href="https://ggxxii.github.io/clothedreamer">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2406.16815">paper</a>
                  /
                  <a href="https://github.com/ggxxii/clothedreamer">code</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 
		
		<tr onmouseout="p3d_stop()" onmouseover="p3d_start()">
		<td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
	                <div class="two" id='p3d_image'><video  width=100% height=100% muted autoplay loop>
	                <source src="videos/p3d.mp4" type="video/mp4">
	                Your browser does not support the video tag.
	                </video></div>
	                <img src='images/p3d.png' width="160">
	              </div>
	              <script type="text/javascript">
	                function p3d_start() {
	                  document.getElementById('p3d_image').style.opacity = "1";
	                }
	
	                function p3d_stop() {
	                  document.getElementById('p3d_image').style.opacity = "0";
	                }
	                p3d_stop()
	              </script>
	            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image</papertitle>
                  <br>
			Jinkun Hao, <strong>Junshu Tang</strong>, Jiangning Zhang, Ran Yi, Yijia Hong, Moran Li, Weijian Cao, Yating Wang, Lizhuang Ma
                  <br>
                                <em>AAAI</em>, 2025
                  <br>
		  <a href="https://jinkun-hao.github.io/Portrait3D/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2406.16710">paper</a>
                  /
                  <a href="https://jinkun-hao.github.io/Portrait3D/">code</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 
		
		
		<tr onmouseout="fastlgs_stop()" onmouseover="fastlgs_start()">
		<td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
	                <div class="two" id='fastlgs_image'>
	                  <img src='images/fastlgs_1.png' width="160"></div>
	                <img src='images/fastlgs_0.png' width="160">
	              </div>
	              <script type="text/javascript">
	                function fastlgs_start() {
	                  document.getElementById('fastlgs_image').style.opacity = "1";
	                }
	
	                function fastlgs_stop() {
	                  document.getElementById('fastlgs_image').style.opacity = "0";
	                }
	                fastlgs_stop()
	              </script>
	            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping</papertitle>
                  <br>
			Yuzhou Ji, He Zhu, <strong>Junshu Tang</strong>, Wuyi Liu, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan
		  <br>
                                <em>AAAI</em>, 2025
                  <br>
		  <a href="https://george-attano.github.io/FastLGS/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2406.01916">paper</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 
		
		<tr onmouseout="free_stop()" onmouseover="free_start()">
		<td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
	                <div class="two" id='free_image'><video  width=100% height=100% muted autoplay loop>
	                <source src="videos/freemotion.mp4" type="video/mp4">
	                Your browser does not support the video tag.
	                </video></div>
	                <img src='images/freemotion.png' width="160">
	              </div>
	              <script type="text/javascript">
	                function free_start() {
	                  document.getElementById('free_image').style.opacity = "1";
	                }
	
	                function free_stop() {
	                  document.getElementById('free_image').style.opacity = "0";
	                }
	                free_stop()
	              </script>
	            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>FreeMotion: A Unified Framework for Number-free Text-to-Motion Synthesis</papertitle>
                  <br>
			Ke Fan, <strong>Junshu Tang</strong>, Weijian Cao, Ran Yi, Moran Li, Jingyu Gong, Jiangning Zhang, Yabiao Wang, Chengjie Wang, Lizhuang Ma
		  <br>
                                <em>ECCV</em>, 2024
                  <br>
		  <a href="https://vankouf.github.io/FreeMotion">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2405.15763">paper</a>
                  /
                  <a href="https://github.com/VankouF/FreeMotion-Codes">code</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 
	     
		<tr onmouseout="tex_stop()" onmouseover="tex_start()">
		<td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
	                <div class="two" id='tex_image'>
	                  <img src='images/texdreamer.png' width="160"></div>
	                <img src='images/texdreamer.png' width="160">
	              </div>
	              <script type="text/javascript">
	                function tex_start() {
	                  document.getElementById('tex_image').style.opacity = "1";
	                }
	
	                function tex_stop() {
	                  document.getElementById('tex_image').style.opacity = "0";
	                }
	                tex_stop()
	              </script>
	            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation</papertitle>
                  <br>
		  Yufei Liu, Junwei Zhu, <strong>Junshu Tang</strong>, Shijie Zhang, Jiangning Zhang, Weijian Cao, Chengjie Wang, Yunsheng Wu, Dongjin Huang
                  <br>
                                <em>ECCV</em>, 2024, Oral
                  <br>
		  <a href="https://ggxxii.github.io/texdreamer/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2403.12906">paper</a>
                  /
                  <a href="https://github.com/ggxxii/TexDreamer">code</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 
		
	   <tr onmouseout="vivid_stop()" onmouseover="vivid_start()">
		<td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
	                <div class="two" id='vivid_image'>
	                  <img src='images/vivid.png' width="160"></div>
	                <img src='images/vivid.png' width="160">
	              </div>
	              <script type="text/javascript">
	                function vivid_start() {
	                  document.getElementById('vivid_image').style.opacity = "1";
	                }
	
	                function vivid_stop() {
	                  document.getElementById('vivid_image').style.opacity = "0";
	                }
	                vivid_stop()
	              </script>
	            </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Make-It-Vivid: Dressing Your Animatable Biped Cartoon Characters from Text</papertitle>
                  <br>
                  <strong>  Junshu Tang </strong>, Yanhong Zeng, Ke Fan, Xuheng Wang, Bo Dai, Kai Chen, Lizhuang Ma
                  <br>
                                <em>CVPR</em>, 2024
                  <br>
		  <a href="https://make-it-vivid.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2403.16897">paper</a>
                  /
                  <a href="https://github.com/junshutang/Make-It-Vivid">code</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 

            <tr onmouseout="bunny_stop()" onmouseover="bunny_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                    <div class="two" id='bunny_image'><video  width=100% height=100% muted autoplay loop>
                    <source src="videos/bunnycake.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                    </video></div>
                    <img src='images/bunnycake.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function bunny_start() {
                      document.getElementById('bunny_image').style.opacity = "1";
                    }
    
                    function bunny_stop() {
                      document.getElementById('bunny_image').style.opacity = "0";
                    }
                    bunny_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior</papertitle>
                  <br>
                  <strong>  Junshu Tang </strong>, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, Dong Chen
                  <br>
                                <em>ICCV</em>, 2023
                  <br>
                  <a href="https://make-it-3d.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2303.14184">paper</a>
                  /
                  <a href="https://github.com/junshutang/Make-It-3D">code</a>
                  <p></p>
                  <p></p>
                </td>
              </tr> 

          <tr onmouseout="cpa_stop()" onmouseover="cpa_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='cpa_image'><video  width=100% height=100% muted autoplay loop>
                <source src="control/static/videos/new_235_interp.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/235_src.png' width="160">
              </div>
              <script type="text/javascript">
                function cpa_start() {
                  document.getElementById('cpa_image').style.opacity = "1";
                }

                function cpa_stop() {
                  document.getElementById('cpa_image').style.opacity = "0";
                }
                cpa_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>3DFaceShop: Explicitly Controllable 3D-Aware Portrait Generation</papertitle>
              <br>
              <strong>  Junshu Tang </strong>, Bo Zhang , Binxin Yang , Ting Zhang , Dong Chen , Lizhuang Ma , Fang Wen
              <br>
							<em>TVCG</em>, 2023
              <br>
              <a href="http://junshutang.github.io/control/index.html">project page</a>
              /
              <a href="https://arxiv.org/pdf/2209.05434">paper</a>
              /
              <a href="https://github.com/junshutang/3DFaceShop">code</a>
              <p></p>
              <p></p>
            </td>
          </tr> 

          <tr onmouseout="pa_stop()" onmouseover="pa_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='pa_image'>
                  <img src='images/pa-fig1.png' width="160" height="100%"></div>
                <img src='images/pa-fig1.png' width="160" height="100%">
              </div>
              <script type="text/javascript">
                function pa_start() {
                  document.getElementById('pa_image').style.opacity = "1";
                }

                function pa_stop() {
                  document.getElementById('pa_image').style.opacity = "0";
                }
                pa_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Prototype-Aware Heterogeneous Task for Point Cloud Completion </papertitle>
              </a>
              <br>
              <strong>  Junshu Tang </strong>, Jiachen Xu, Jingyu Gong, Haichuan Song, Yuan Xie, Lizhuang Ma
              <br>
              <em> CAD/Graphics </em>, 2023   
              <br>
              <a href="https://arxiv.org/abs/2209.01733">paper</a> 
              <p></p>
             </p>
            </td>
          </tr>    

          <tr onmouseout="LAKE_stop()" onmouseover="LAKE_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='lake_image'>
                  <img src='images/lake-fig1.png' width="160" height="100%"></div>
                <img src='images/lake-fig1.png' width="160" height="100%">
              </div>
              <script type="text/javascript">
                function LAKE_start() {
                  document.getElementById('lake_image').style.opacity = "1";
                }

                function LAKE_stop() {
                  document.getElementById('lake_image').style.opacity = "0";
                }
                lake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> LAKe-Net: Topology-Aware Point Cloud Completion by Localizing Aligned Keypoints </papertitle>
              </a>
              <br>
              <strong>  Junshu Tang </strong>, Zhijun Gong, Ran Yi, Yuan Xie, Lizhuang Ma 
              <br>
              <em> CVPR</em>, 2022   
              <br>
              <a href="https://arxiv.org/abs/2203.16771">paper</a> / 
              <a href="https://github.com/junshutang/LAKe-Net">code</a>  
              <p></p>
             </p>
            </td>
          </tr>               
          

          <tr onmouseout="drte_stop()" onmouseover="drte_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='drte_image'>
                  <img src='images/drte_start.png' width="160"></div>
                <img src='images/drte_end.png' width="160">
              </div>
              <script type="text/javascript">
                function drte_start() {
                  document.getElementById('drte_image').style.opacity = "1";
                }

                function drte_stop() {
                  document.getElementById('drte_image').style.opacity = "0";
                }
                drte_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Explicit facial expression transfer via fine-grained semantic representations </papertitle>
              </a>
              <br>
              Zhiwen Shao, Hengliang Zhu, <strong>  Junshu Tang </strong>, Xuequan Lu, and Lizhuang Ma 
              <br>
              <em> TIP </em>, 2021
              <br>
              <a href="https://arxiv.org/abs/1909.02967">paper</a> 
              <!-- <a href="https://github.com/junshutang/LAKe-Net">code</a>   -->
              <p></p>
             </p>
            </td>
          </tr>     
          

            <tr onmouseout="eggan_stop()" onmouseover="eggan_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; justify-content: center; position: relative;">
                <div class="two" id='eggan_image'>
                  <img src='images/eggan.png' width="160"></div>
                <img src='images/eggan.png' width="160">
              </div>
              <script type="text/javascript">
                function eggan_start() {
                  document.getElementById('eggan_image').style.opacity = "1";
                }

                function eggan_stop() {
                  document.getElementById('eggan_image').style.opacity = "0";
                }
                eggan_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle> Fine-grained expression manipulation via structured latent space. </papertitle>
              </a>
              <br>
              <strong>  Junshu Tang </strong>, Zhiwen Shao, Lizhuang Ma 
              <br>
              <em> ICME Oral Presentation</em>, 2020   
              <br>
              <a href="https://arxiv.org/abs/2004.09769">paper</a> / 
              <a href="https://github.com/junshutang/EGGAN">code</a>   
              <p></p>
             </p>
            </td>
          </tr> 

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
                <ul>
                  <li>Reviewers: SIGGRAPH, CVPR, ICCV, ECCV, NeurIPS, TPAMI, TIP, AAAI, IJCAI, ACM MM, 3DV, BMVC, TNNLS, ICME.
                </ul>
            </td>
          </tr>
        </tbody></table>
                                                                      
                                                                                   
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Awards      </heading>
                <ul>
		  <li> Outstanding Graduates, Shanghai Jiao Tong University </li>
		  <li> Stars of Tomorrow Internship Program, Microsoft Research Asia </li>
		  <li> Wen-Tsun Wu Honorary Scholarship, Shanghai Jiao Tong University </li>
                  <li> National Scholarship, Education Ministry of China </li>
                  <li> Outstanding Graduates, Xidian University </li>
                  <li> First-Class Scholarship, Xidian University </li>
                </ul>
           </td>
          </tr>
        </tbody></table>                                                                                       
                                                                                       
                                                                                       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">Thanks to <a href="https://jonbarron.info/"> Jon Barron</a> for sharing the code of his personal webpage.</p>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>


<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?lili9707"
border="0" alt="Hit Counters"></a>
<br><a href="https://www.easycounter.com/">page counter</a>
  

</html>
